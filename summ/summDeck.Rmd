---
title: ICC Initial Modeling Deck
author: "Shahryar Minhas"
date: "3/22/2018"
output:
  xaringan::moon_reader:
    css: "slides.css"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
exclude: true

```{r, message=FALSE, warning=FALSE, include=FALSE}
options(
  htmltools.dir.version = FALSE, # for blogdown
  width = 80,
  tibble.width = 80
)

knitr::opts_chunk$set(
  fig.align = "center"
)

library(emo)
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
```

```{r setup, message=FALSE}
library(ggplot2)
theme_set(theme_bw())
library(dplyr)
library(stringr)
library(magrittr)
library(rvest)
```

---
class: middle
count: false

# Data

---

## DVs

- State
  + Prelim ICC Involvement: 18 countries experienced event between 2002 to 2016
  + Formal ICC Involvement: 5 countries experienced event between 2002 to 2016

- Opposition
  + Prelim ICC Involvement: 16 countries experienced event between 2002 to 2016
  + Formal ICC Involvement: 8 countries experienced event between 2002 to 2016

---

## IVs

- ICC ratification
- Africa region binary (static)
- GDP in constant dollars from World Bank (to 2017)
- Civil War & OSV from UCDP (to 2016)
- Political Terror Scale (to 2016)
- Polity (to 2016)
- Lower and higher court independence measures from VDEM (to 2017)
- Referral data (static)

---

## P5+1 Measures

For each P5+1 measure, I calculate the average relationship between every country in the sample and also include individual variables designating the relation between a country and each of the P5+1 countries.

- Ideal points from Voeten (to 2015)
- Military intervention from UCDP (to 2016)

Other affinity measures with P5+1 countries that we discussed include alliances, joint IGO membership, and trade. Each of these variables has too short a time series. I have the SIPRI measure set up as well but am hesitant about using it for now because the level of missingness in the dataset exceeds 30%.

---

## Effective sample

- Lagging each of the IVs and P5+1 measures by one year provides us with an effective sample from 2002 to 2016. 
- Each of the control and key variables of interest come with degrees of missingness, but in no case do we have missingness for more than 10% of cases. 
- However, given that some of those missing cases will lead us to lose the already number of rare events that we have I imputed five missing datasets using a Bayesian copula scheme. 

---

# Modeling

---

## Major issues to keep in mind

- Very few countries experience prelim and even fewer experience formal
- There might be a sample selection issue in that countries may only experience formal after a prelim. 

---

## Strategies

- We've discussed a number of modeling strategies:
  + Logit models estimated separately for prelim and formal stage
  + Logit model with temporal dependence taken into account using cubic splines (Carter & Signorino, 2010)
  + Selection model to account for the conditional dependence between the formal and prelim stages
  + Matching strategies given the covariates we assembled
  + Random forest models to aid in accounting for paucity of events

---

## Aside on selection models

I tried setting up a Heckman selection model with varying covariates in the prelim and formal stages but the correlation across the equations tended to be above 0.8 no matter the specification. I switched to a Sartori model, which doesn't require different DGPs for the selection and outcome stages. 

However, this approach comes with a key assumption of its own: the error term for an observation must be the same in the two equations. 

---

## Aside on matching

Some in the literature have talked about using matching as an alternative to dealing with selection bias. I doubt that we have the sample to actually employ this procedure. Also we would have to make an argument here that we can account for the selection bias by matching on the observables that we have collected. 

---

## Model specification

In general, the model specification I used for the Sartori and logistic models is: 

ICC (prelim/formal, state/opp): 

Africa + ICC + GDP + Ratification + OSV + Intervention + Civil War + Democracy + Higher Judicial + Avg P5 Voting Sim + Higher Judicial x Avg P5 Voting Sim

- I use the higher judicial measure from VDEM instead of the lower because across the logit and sartori models they provided me consistent results. 
- Haven't included the PTS variables yet.
- Referral information has not been incorporated into the model yet either. 

---

## Notes before results

- As you can see there are a lot of covariates here and we also have an interactive relationship to test as well
- This is important to note as the number of actual events is so small
- Also because our DVs are binary as well I'm concerned about separation issues
- There is a way of dealing with separation issues by building on prior information about the parameters in the model ... but how we set priors here is unclear to me, especially, when we get to the Sartori model. 

---

## Logistic model: ICC Prelim

Sorry for the crude depiction, but blue/red indicates significance at 95% CI. Haven't had a chance to do a substantive effects analysis yet, and also as I've been trying to note above I'm not the most confident in these results just yet. 

.pull-left[
Government - Prelim
- Africa
- ICC Ratif. 
- GDP
- <span style="color:blue">OSV</span>
- Intervention
- <span style="color:blue">Civil War</span>
- Democracy
- <span style="color:red">Judicial</span>
- P5 Voting
- Judicial x P5 Voting
]

.pull-right[
Opposition - Prelim
- Africa
- ICC Ratif.
- GDP
- Ratification
- <span style="color:blue">OSV</span>
- Intervention
- Civil War
- Democracy
- <span style="color:red">Judicial</span>
- P5 Voting
- Judicial x P5 Voting
]

---

## Logistic model: ICC Formal

.pull-left[
Government
- <span style="color:blue">Africa</span>
- <span style="color:blue">ICC</span>
- GDP
- Ratification
- <span style="color:blue">OSV</span>
- Intervention
- Civil War
- Democracy
- <span style="color:red">Judicial</span>
- <span style="color:red">P5 Voting</span>
- Judicial x P5 Voting
]

.pull-right[
Opposition
- <span style="color:blue">Africa</span>
- <span style="color:blue">ICC</span>
- GDP
- Ratification
- <span style="color:blue">OSV</span>
- Intervention
- Civil War
- Democracy
- Judicial
- P5 Voting
- Judicial x P5 Voting
]

---

## Sartori model: Government

.pull-left[
Prelim
- <span style="color:blue">Africa</span>
- <span style="color:blue">ICC</span>
- GDP
- Ratification
- <span style="color:blue">OSV</span>
- Intervention
- Civil War
- Democracy
- <span style="color:red">Judicial</span>
- <span style="color:red">P5 Voting</span>
- Judicial x P5 Voting
]

.pull-right[
Formal
- <span style="color:blue">Africa</span>
- <span style="color:blue">ICC</span>
- GDP
- Ratification
- <span style="color:blue">OSV</span>
- Intervention
- Civil War
- Democracy
- Judicial
- P5 Voting
- Judicial x P5 Voting
]

---

## Sartori model: Rebel

.pull-left[
Prelim
- <span style="color:blue">Africa</span>
- ICC
- GDP
- Ratification
- <span style="color:blue">OSV</span>
- Intervention
- Civil War
- Democracy
- <span style="color:red">Judicial</span>
- P5 Voting
- Judicial x P5 Voting
]

.pull-right[
Formal
- <span style="color:blue">Africa</span>
- <span style="color:blue">ICC</span>
- GDP
- Ratification
- <span style="color:blue">OSV</span>
- Intervention
- Civil War
- Democracy
- Judicial
- P5 Voting
- Judicial x P5 Voting
]

---

## Weighing the models

I also generated predictions from each of these models in a leave one out cross validation context. This is a common way of assessing how well the models perform in being able to generate the data in an out of sample context. The logistic and Sartori models each perform quite poorly. The metrics that we would use to study prediction in the binary case are ROC and PR curves, and for each of the models above the AUC under these curves was less than 0.6. A value of 0.5 would indicate that you're better simply tossing a coin. 



